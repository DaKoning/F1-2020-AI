In main() na start functie toegevoegd die ervoor zorgt dat de game pauseert, zodat data_collection automatisch stopt
no_speed_punishment toegevoegd
Qlearning geeft alleen dezelfde acties als dezelfde state al bestaat, anders worden het random acties
Vervang de Q-waarde in de Q-table ipv opnieuw toevoegen, zodat de future_state nog steeds makkelijk bepaald kan worden
Als de lap gerestart gaat worden, wordt de future state niet bepaald, aangezien deze er niet is. De future state Q-waarde wordt 0.

Q-learning 2.0: De Q-waarde moet bepaald worden n√°dat de actie is uitgevoerd, dus bij de volgende tijdsstap, dus ik heb heel Qlearning.py omgegooid om dat waar te maken 

Q-learning 3.0: De Q-value van de future state wordt nu bepaald aan de hand van de state die het meest lijkt op de current state (hiermee wordt de Q-waarde van de vorige state bepaald)

Wanneer de lap invalid is, wordt de Q_max 0, zodat deze slechte actie geen hoge Q-waarde krijgt omdat de staat na de restart wel een goede staat is
De AI mag 1x te traag zijn, de tweede keer wordt het script gestopt (voor computerhaperingen)
De totale tijd van de AI wordt nu bijgehouden