# Vergelijkt de current state met alle states in de Q-table en berekent de state in de Q-table die het meest op de current state lijkt
Q_table_state = Q_table[:, :6] # Q_table_state is the state part of the Q-table without the headers 
state_resized = np.resize(state, (Q_length, 6)) # Make a two dimensional array of the state repeated, where the length is the length of the Q-table, so that we can subtract them
subtracted_array = np.subtract(Q_table_state, state_resized) # The differences between the states in the Q-table and the current state
average_array = np.absolute(np.average(subtracted_array, axis=1)) # The averages of the differences per state, in absolutes so that we can determine the lowest average
Q_array = Q_table[:, 9] # Array of the Q-values of each row in the Q-table
score_array = np.divide(Q_array, average_array + 1) # Array of the score of each row in the Q-table
best_row_index = np.argmax(score_array) # The index of the row of the Q-table that has the highest score
        
future_state_index = best_row_index + 1 # De voorspelling voor de volgende state wordt gelijk gesteld aan de state die volgt op de state die het meest op de huidige state lijkt

# Als de future state van de best row bestaat, nemen we daarvan de Q-waarde, anders nemen we de Q-waarde van de resemblance state zelf
if 0 <= future_state_index < Q_length - 1:
    Q_max = Q_table[future_state_index][9]
else:
    Q_max = Q_table[best_row_index][9]

actions, epsilon = determine_action(Q_table, best_row_index, epsilon)
throttle, brakes, steering = actions
